---
title: "Who Said The AI ML Was Fair?"
description: ''
date: 2023-08-21 00:57:53.750145+00:00
---

This week we take a look at fairness in A.I. and M.L. and F.A.I.R. data.

This week's musical inspiration in title and lyrics:

https://open.spotify.com/track/6me09fq5f0q9l132jjWQM4?si=52a272c153dd4ced

# Getting Informed

If all is fair in love and war... then what about AI and ML or data? ğŸ¤”

To be \_fair\_, there is a lot of work being done by the word \_fair\_ this week. Indeed, one could argue that the \_fair\_ within AI ML concerns of fairness specifically apply when and where a \_fare\_ is assessed to be paid by the world, humanity, and future generations for their own data. ğŸ§

FAIR is not a backronym for Frequently Amorphous Inherent Rigamarole. At least, I hope not. ğŸ¤“

This week I read, listened, and watched a bit more than usual. Here are my reading ğŸ“–, watching ğŸ“º, and listening ğŸ§ suggestions:

- [ğŸ“– Developing Trustworthy Software Tools](https://newsletter.abinoda.com/p/trustworthy-developer-tools) in which [Abi Noda](https://www.linkedin.com/in/abinoda/) digests the [PICSE Framework](https://www.microsoft.com/en-us/research/publication/the-picse-framework-for-trust-in-software-tools/) paper from [Brittany Johnson-Matthews, Ph.D.](https://www.linkedin.com/in/brittany-i-johnson-phd/), [Christian Bird](https://www.linkedin.com/in/christian-bird-1896494/), [Denae Ford Robinson, Ph.D.](https://www.linkedin.com/in/denaefordrobinson/), [Nicole Forsgren](https://www.linkedin.com/in/nicolefv/), and [Tom Zimmermann](https://www.linkedin.com/in/tomzimmermann/).
- [ğŸ“– Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness](https://proceedings.mlr.press/v80/kearns18a.html) in which [Michael Kearns](https://www.linkedin.com/in/michael-kearns-0951337/), [Seth Neel](https://www.linkedin.com/in/sethneelwelligence/), [Aaron Roth](https://www.linkedin.com/in/aaron-roth-b7a6552b/), and [Zhiwei Steven Wu](https://www.linkedin.com/in/zstevenwu/) make the case for a more effective auditing of constraints.
- [ğŸ“– Inherent Limitations of AI Fairness](https://arxiv.org/abs/2212.06495) in which [Maarten Buyl](https://www.linkedin.com/in/maarten-buyl-44a54715a/) and [Tijl De Bie](https://www.linkedin.com/in/tijldebie/) provide a summary of wider AI fairness critiques to inform future research in the pursuit of improving fairness.
- [ğŸ§ Understanding Machine Learning Features and Platforms](https://www.thecloudcast.net/2023/08/understanding-machine-learning-features.html) in which [Aaron Delp](https://www.linkedin.com/in/aarondelp/) and [Brian Gracely](https://www.linkedin.com/in/briangracely/) interview [Gaetan Castelein](https://www.linkedin.com/in/gaetan-castelein/).
- [ğŸ§ Making Research Data FAIR](https://velocityofcontentpodcast.com/transcripts/making-research-data-fair/) in which [Christopher Kenneally](https://www.linkedin.com/in/christopher-kenneally-boston/) interviews [George Strawn](https://www.linkedin.com/in/george-strawn-8a1171/), [Barend Mons](https://www.linkedin.com/in/barend-mons-phd-a494142/), [Christine Kirkpatrick](https://www.linkedin.com/in/kirkpatrickchristine/), [Erik Schultes](https://www.linkedin.com/in/erik-schultes-39aa8ab/), [Francisca Oladipo](https://www.linkedin.com/in/francisca-o-oladipo-0b6b0715/), and [Debora Drucker](https://www.linkedin.com/in/debora-drucker/) on the history, present, and future of data based upon [Findable Accessible Interoperable Reusable (FAIR) principles](https://www.go-fair.org/fair-principles/) vs. confusion with Fully AI Ready (FAIR) data assumptions... as well as [FAIR Digital Objects Forum](https://fairdo.org) and [FAIR in Machine Learning, AI Reproducibility, and AI Readiness (FARR)](https://www.farr-rcn.org) â€” soooooo good â€” this discussion is one I'm saving to my podcast app for re-re-listening.
- [ğŸ“º Uncovering the Practices and Opportunities for Cross-functional Collaboration around AI Fairness](https://www.youtube.com/watch?v=0IX8c7OfiiE) in which [Wesley Hanwen Deng](https://www.linkedin.com/in/wesley-deng-891961231/) provides a summary of [recent work on AI fairness](https://dl.acm.org/doi/abs/10.1145/3593013.3594037) with [Nur Yildirim](https://www.linkedin.com/in/yildirimnur/), [Monica Chang](https://www.linkedin.com/in/monicachang1/), [Motahhare Eslami](https://www.linkedin.com/in/motahhareeslami/), [Kenneth Holstein](https://www.linkedin.com/in/ken-holstein-b5668216a/) and [Michael Madaio](https://www.linkedin.com/in/mmadaio/).
- [ğŸ“º Cloud vs. On-Prem Showdown: The Future Battlefield for Generative AI Dominance](https://www.youtube.com/watch?v=U0ZSv9Y7RSU) in which [Dave Vellante](https://www.linkedin.com/in/dvellante/) breaks down how spending momentum in AI is changing based upon the latest ETR data.

## The sun is free enough ğŸ¶

I'm reminded that [FAIR principles](https://www.go-fair.org/fair-principles/) are less than a decade old. That's young in IT terms.

As I've said before... ethics and empathy are needed.

https://fudge.org/archive/esteem-is-stem-plus-ethics-plus-empathy/

## But if they can, they'll find a way ğŸ¶

Dystopian fever dreams aside, it can be useful to imagine a system of perverse market incentives that drive opaquely enriched data to become more closed, more proprietary, more paywalled, and more about short term extraction than balanced long term local enlightenment as well as global enlightenment. Indeed, we must continuously balance market demands with the pursuit of science, applied technology, and our evolving human values.

Seeking fairness in AI/ML pursuits and FAIR data frameworks could easily be part of how we govern ourselves in the future â€” or not. Without both, it is not clear how auditing would be possible and could reduce terms such as transparency to being little more than an early 2000s era platitude that exited the zeitgeist almost as soon as it entered.

So, what will be the next big thing in AI/ML fairness and FAIR data?

Until thenâ€¦ Place your bets!

# Disclosure

I am linking to my [disclosure](https://jaycuthrell.com/disclosure/).

ğŸ¤“